{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import GPy\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from visualize import *\n",
    "from calibration import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_BINS = 10\n",
    "N = 1000 # takes value from 1 to 10000\n",
    "NUM_CLASSES =  100\n",
    "NUM_CLASSES_PLOT = 4\n",
    "NUM_COL = 2\n",
    "METHOD_NAME = \"binary_gp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load prediction from ResNet on CIFAR100 test data, which contains 10,000 images. \n",
    "# https://github.com/rloganiv/pytorch-classification/blob/master/predict.py\n",
    "# data: a numpy array of size 10,000 * 101. For each row, the first entry is the true label,\n",
    "#       following by softmax of output logits of this image for each class.\n",
    "data = np.genfromtxt(\"data/cifar100_predictions_dropout.txt\")[0:N,:]# 10000*101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = data[:,1:]\n",
    "Y_predict = np.argmax(p, axis=1)\n",
    "Y_true = data[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GPC to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learned kernel: RBF(length_scale=0.05)\n",
      "\n",
      "Learned kernel: RBF(length_scale=0.05)\n",
      "\n",
      "Learned kernel: RBF(length_scale=0.05)\n",
      "\n",
      "Learned kernel: RBF(length_scale=0.101)\n",
      "\n",
      "Learned kernel: RBF(length_scale=0.05) + 5.09**2 * RBF(length_scale=0.747)\n"
     ]
    }
   ],
   "source": [
    "# GPC with SKlearn\n",
    "KERNELS = [RBF(0.1, (0.05, 1)), \n",
    "           RBF(0.1, (0.05, 1)) + 10**2 * RBF(1), \n",
    "           RBF(0.1, (0.05, 1)) + 10**2 * RBF(1) + 100.0 * DotProduct(sigma_0=1.0)]\n",
    "for kernel in KERNELS:\n",
    "    f, ax = plt.subplots(NUM_CLASSES_PLOT/NUM_COL, NUM_COL, sharex='col', sharey='row')\n",
    "    f.set_figheight(5)\n",
    "    f.set_figwidth(5)\n",
    "    for K in range(NUM_CLASSES_PLOT):\n",
    "        ax[K/NUM_COL, K%NUM_COL] = gpc_sklearn(ax[K/NUM_COL, K%NUM_COL],\n",
    "                                                 p[:,K],\n",
    "                                                 np.array((Y_true == K)) * 1,\n",
    "                                                 kernel)\n",
    "    f.tight_layout()\n",
    "    #f.savefig(\"figures/%s/reliability_per_class.png\" % METHOD_NAME)\n",
    "    #f.savefig(\"figures/%s/reliability_per_class.eps\" % METHOD_NAME, format='eps',dpi=1000)\n",
    "    #plt.legend(('Data', 'Isotonic Fit', 'Linear Fit'), loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gpc_gpy(ax, x, y, kernel):\n",
    "    \"\"\"\n",
    "    Implemented with GPy\n",
    "    \n",
    "    INPUT:\n",
    "        ax: an Axes object\n",
    "        x: (N, ) np.array\n",
    "        y: (N, ) np.array\n",
    "        kernel:\n",
    "    OUTPUT:\n",
    "        ax: an Axes object\n",
    "    \"\"\"\n",
    "    # Fit GaussianProcessClassification and LinearRegression models\n",
    "    m = GPy.core.GP(\n",
    "        X=x[:, np.newaxis],\n",
    "        Y=y[:, np.newaxis],\n",
    "        kernel=kernel, \n",
    "        inference_method=GPy.inference.latent_function_inference.expectation_propagation.EP(),\n",
    "        likelihood=GPy.likelihoods.Bernoulli()\n",
    "    )\n",
    "    print m, '\\n'\n",
    "    for i in range(5):\n",
    "        m.optimize('bfgs', max_iters=100) #first runs EP and then optimizes the kernel parameters\n",
    "        print 'iteration:', i,\n",
    "        print m\n",
    "        print \"\"\n",
    "    y_ = m.predict(x[:, np.newaxis])[0]\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x[:, np.newaxis], y)  # x needs to be 2d for LinearRegression\n",
    "    \n",
    "    # Plot data, p(y=1|x) in GPC, linear regression\n",
    "    m.plot()\n",
    "    ax.plot(x, y, 'r.', markersize=12, alpha = 0.2)\n",
    "    ax.plot(x, y_, 'b^', markersize=12, alpha = 0.2)\n",
    "    ax.plot(x, lr.predict(x[:, np.newaxis]), 'b-')\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    \n",
    "    # Plot \n",
    "    \n",
    "    # compute ece and acc after calibration\n",
    "    ece = EceEval(np.array([1-y_, y_]).T , y, num_bins = 20)\n",
    "    y_predict = y_ > 0.5\n",
    "    acc = (y_predict == y).mean()\n",
    "    \n",
    "    ax.text(0.05, 0.8, 'ECE=%.4f\\nACC=%.4f'% (ece, acc), size=14, ha='left', va='center',\n",
    "            bbox={'facecolor':'green', 'alpha':0.5, 'pad':4})\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GPC with GPy\n",
    "KERNELS = [GPy.kern.RBF(1, variance=5., lengthscale=0.1) + GPy.kern.Linear(1)]\n",
    "for kernel in KERNELS:\n",
    "    f, ax = plt.subplots(NUM_CLASSES_PLOT/NUM_COL, NUM_COL, sharex='col', sharey='row')\n",
    "    f.set_figheight(5)\n",
    "    f.set_figwidth(5)\n",
    "    \n",
    "    for K in range(NUM_CLASSES_PLOT):\n",
    "        ax[K/NUM_COL, K%NUM_COL] = gpc_gpy(ax[K/NUM_COL, K%NUM_COL],\n",
    "                                                 p[:,K],\n",
    "                                                 np.array((Y_true == K)) * 1,\n",
    "                                                 kernel)\n",
    "    f.tight_layout()\n",
    "    #f.savefig(\"figures/%s/reliability_per_class.png\" % METHOD_NAME)\n",
    "    #f.savefig(\"figures/%s/reliability_per_class.eps\" % METHOD_NAME, format='eps',dpi=1000)\n",
    "    #plt.legend(('Data', 'Isotonic Fit', 'Linear Fit'), loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
